# Web Scraping: Pr치ctica Paso a Paso

Este repositorio contiene una serie de ejercicios pr치cticos sobre Web Scraping, realizados paso a paso con `requests`, `BeautifulSoup` y el manejo de datos obtenidos de sitios web. El objetivo de esta pr치ctica fue comprender los conceptos b치sicos del scraping y aplicarlos de manera estructurada.

## Tecnolog칤as Utilizadas

- **Python**: Lenguaje de programaci칩n principal.
- **Requests**: Para obtener el contenido HTML de las p치ginas web.
- **BeautifulSoup**: Para parsear y analizar el HTML.
- **CSV**: Para almacenar los datos extra칤dos en archivos estructurados.

## Conceptos Clave Aprendidos

- **Entendimos el DOM**: Estructura de una p치gina web y sus nodos.
- **Usamos `requests`**: Para descargar contenido de una p치gina web.
- **Parseamos con `BeautifulSoup`**: Accediendo a etiquetas HTML.
- **Utilizamos selectores CSS**: (`.select()`, `#id`, `.class`).
- **Iteramos con `for` y `enumerate()`**: Para mostrar contenido estructurado.
- **Guardamos los datos en un archivo CSV**: Con `csv.writer()`.

## Ejercicios Realizados

### 1. Scraping B치sico
- Descargamos el contenido de una p치gina web con `requests`.
- Analizamos el HTML con `BeautifulSoup`.
- Extra칤mos informaci칩n usando `.title`, `.text`, `.find_all()`.

### 2. Uso de Selectores CSS
- Aplicamos `soup.select()` para buscar elementos con selectores avanzados.
- Filtramos informaci칩n por etiquetas, clases e IDs.
- Mostramos s칩lo un subconjunto de datos relevantes.

### 3. Iteraci칩n y Extracci칩n de Enlaces
- Extra칤mos y listamos enlaces de una p치gina web.
- Usamos `href=True` para filtrar enlaces v치lidos.
- Iteramos con `enumerate()` para numerar los resultados.

### 4. Guardado de Datos en CSV
- Convertimos la informaci칩n extra칤da en datos estructurados.
- Guardamos los datos en un archivo `.csv`.
- Utilizamos `csv.writer()` para escribir los datos en filas y columnas.

## C칩mo Usarlo
1. Clona el repositorio:
   ```bash
   git clone https://github.com/tu-usuario/tu-repo.git
   ```
2. Instala las dependencias necesarias:
   ```bash
   pip install -r requirements.txt
   ```
3. Ejecuta los scripts:
   ```bash
   python scraping_basico.py
   ```

## Siguientes Pasos
La siguiente etapa de esta pr치ctica incluir치 el uso de **Selenium** para interactuar con p치ginas web din치micas y, eventualmente, la creaci칩n de una interfaz gr치fica con **PyQt**.

---
九꽲잺 *Este proyecto es parte de mi proceso de aprendizaje en Web Scraping. Cualquier sugerencia o mejora es bienvenida.* 游

